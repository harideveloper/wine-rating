{
  "components": {
    "comp-condition-1": {
      "dag": {
        "tasks": {
          "deploy-to-vertex-endpoint": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-deploy-to-vertex-endpoint"
            },
            "dependentTasks": [
              "register-model"
            ],
            "inputs": {
              "artifacts": {
                "model_registry_name": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "registered_model",
                    "producerTask": "register-model"
                  }
                }
              },
              "parameters": {
                "endpoint_display_name": {
                  "componentInputParameter": "pipelinechannel--endpoint_display_name"
                },
                "project": {
                  "componentInputParameter": "pipelinechannel--project"
                },
                "region": {
                  "componentInputParameter": "pipelinechannel--region"
                }
              }
            },
            "taskInfo": {
              "name": "deploy-to-vertex-endpoint"
            }
          },
          "register-model": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-register-model"
            },
            "dependentTasks": [
              "upload-model"
            ],
            "inputs": {
              "artifacts": {
                "model_artifact": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "uploaded_model_artifact",
                    "producerTask": "upload-model"
                  }
                }
              },
              "parameters": {
                "model_display_name": {
                  "componentInputParameter": "pipelinechannel--model_display_name"
                },
                "project": {
                  "componentInputParameter": "pipelinechannel--project"
                },
                "region": {
                  "componentInputParameter": "pipelinechannel--region"
                }
              }
            },
            "taskInfo": {
              "name": "register-model"
            }
          },
          "upload-model": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-upload-model"
            },
            "inputs": {
              "artifacts": {
                "model_artifact": {
                  "componentInputArtifact": "pipelinechannel--train-model-output_model"
                }
              }
            },
            "taskInfo": {
              "name": "upload-model"
            }
          }
        }
      },
      "inputDefinitions": {
        "artifacts": {
          "pipelinechannel--train-model-output_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "pipelinechannel--endpoint_display_name": {
            "parameterType": "STRING"
          },
          "pipelinechannel--evaluate-model-Output": {
            "parameterType": "NUMBER_DOUBLE"
          },
          "pipelinechannel--evaluation_threshold": {
            "parameterType": "NUMBER_DOUBLE"
          },
          "pipelinechannel--model_display_name": {
            "parameterType": "STRING"
          },
          "pipelinechannel--project": {
            "parameterType": "STRING"
          },
          "pipelinechannel--region": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-deploy-to-vertex-endpoint": {
      "executorLabel": "exec-deploy-to-vertex-endpoint",
      "inputDefinitions": {
        "artifacts": {
          "model_registry_name": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "endpoint_display_name": {
            "parameterType": "STRING"
          },
          "project": {
            "defaultValue": "dev2-ea8f",
            "isOptional": true,
            "parameterType": "STRING"
          },
          "region": {
            "defaultValue": "europe-west2",
            "isOptional": true,
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "endpoint": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-evaluate-model": {
      "executorLabel": "exec-evaluate-model",
      "inputDefinitions": {
        "artifacts": {
          "model_artifact": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          },
          "test_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "NUMBER_DOUBLE"
          }
        }
      }
    },
    "comp-load-data": {
      "executorLabel": "exec-load-data",
      "inputDefinitions": {
        "parameters": {
          "data_path": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-preprocess-data": {
      "executorLabel": "exec-preprocess-data",
      "inputDefinitions": {
        "artifacts": {
          "input_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "test_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "train_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-register-model": {
      "executorLabel": "exec-register-model",
      "inputDefinitions": {
        "artifacts": {
          "model_artifact": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "model_display_name": {
            "parameterType": "STRING"
          },
          "project": {
            "defaultValue": "dev2-ea8f",
            "isOptional": true,
            "parameterType": "STRING"
          },
          "region": {
            "defaultValue": "europe-west2",
            "isOptional": true,
            "parameterType": "STRING"
          },
          "serving_container_image_uri": {
            "defaultValue": "europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest",
            "isOptional": true,
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "registered_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-train-model": {
      "executorLabel": "exec-train-model",
      "inputDefinitions": {
        "artifacts": {
          "train_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-upload-model": {
      "executorLabel": "exec-upload-model",
      "inputDefinitions": {
        "artifacts": {
          "model_artifact": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "uploaded_model_artifact": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    }
  },
  "deploymentSpec": {
    "executors": {
      "exec-deploy-to-vertex-endpoint": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "deploy_to_vertex_endpoint"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform>=1.22.1' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef deploy_to_vertex_endpoint(\n    model_registry_name: Input[Model],\n    endpoint: Output[Model],\n    endpoint_display_name: str,\n    project: str = \"dev2-ea8f\",\n    region: str = \"europe-west2\"\n):\n    \"\"\"Deploys a model to Vertex AI Endpoint.\"\"\"\n    from google.cloud import aiplatform\n\n    # Initialize Vertex AI\n    aiplatform.init(project=project, location=region)\n\n    # Get the model resource name\n    model_name = model_registry_name.metadata.get(\"resource_name\")\n    if not model_name:\n        print(f\"\u274c Error: Model resource_name not found in metadata.\")\n        raise ValueError(\"Model resource_name is missing from metadata.\")\n\n    try:\n        model = aiplatform.Model(model_name)\n        print(f\"\u2705 Retrieved model: {model.resource_name}\")\n    except Exception as e:\n        print(f\"\u274c Error retrieving model: {e}\")\n        raise e\n\n    deployed_model_display_name = f\"{model_registry_name.metadata.get('display_name', 'model')}-deployed\"\n\n    try:\n        # Check if endpoint already exists\n        endpoints = aiplatform.Endpoint.list(\n            filter=f'display_name=\"{endpoint_display_name}\"',\n            order_by=\"create_time desc\",\n            project=project,\n            location=region,\n        )\n\n        if endpoints:\n            endpoint_to_use = endpoints[0]\n            print(\n                f\"\u26a0\ufe0f Using existing endpoint: {endpoint_to_use.resource_name}\")\n        else:\n            endpoint_to_use = aiplatform.Endpoint.create(\n                display_name=endpoint_display_name,\n                project=project,\n                location=region\n            )\n            print(f\"\u2705 Created new endpoint: {endpoint_to_use.resource_name}\")\n\n        # Deploy the model\n        print(f\"Starting deployment of model to endpoint...\")\n        endpoint_to_use.deploy(\n            model=model,\n            deployed_model_display_name=deployed_model_display_name,\n            machine_type=\"n1-standard-2\",\n            min_replica_count=1,\n            max_replica_count=1,\n            traffic_split={\"0\": 100}\n        )\n\n        print(f\"\u2705 Model deployed to endpoint: {endpoint_to_use.resource_name}\")\n        endpoint.uri = endpoint_to_use.resource_name\n\n    except Exception as e:\n        print(f\"\u274c Deployment error: {e}\")\n        # If endpoint was created, still save its URI\n        if 'endpoint_to_use' in locals():\n            endpoint.uri = endpoint_to_use.resource_name\n        raise e\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-evaluate-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "evaluate_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas==1.5.3' 'numpy==1.23.5' 'scikit-learn==1.0.1' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef evaluate_model(\n    model_artifact: Input[Model],\n    test_data: Input[Dataset]\n) -> float:\n    \"\"\"Evaluates the wine rating prediction model.\"\"\"\n    import os\n    import pickle\n    import pandas as pd\n    import numpy as np\n    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n    # Load the model\n    model_path = model_artifact.path + \".pkl\"\n    print(f\"Loading model from: {model_path}\")\n\n    try:\n        with open(model_path, 'rb') as file:\n            model = pickle.load(file)\n        print(\"\u2705 Model loaded successfully\")\n    except Exception as e:\n        print(f\"\u274c Error loading model: {e}\")\n        raise\n\n    # Load test data\n    test_df = pd.read_csv(test_data.path)\n    print(f\"\u2705 Loaded test data with shape: {test_df.shape}\")\n\n    # Get features from model metadata\n    features_str = model_artifact.metadata.get(\"features\", \"\")\n    if features_str:\n        import ast\n        features = ast.literal_eval(features_str)\n    else:\n        # Fallback to default features\n        categorical_features = ['Country', 'Region', 'Type', 'Style', 'Grape']\n        categorical_features = [\n            col for col in categorical_features if col in test_df.columns]\n        numeric_features = ['price_numeric']\n        numeric_features = [\n            col for col in numeric_features if col in test_df.columns]\n        features = numeric_features + categorical_features\n\n    target = model_artifact.metadata.get(\"target\", \"Rating\")\n\n    # Make predictions\n    X_test = test_df[features]\n    y_test = test_df[target]\n\n    y_pred = model.predict(X_test)\n\n    # Calculate metrics\n    mse = mean_squared_error(y_test, y_pred)\n    rmse = np.sqrt(mse)\n    mae = mean_absolute_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n\n    print(f\"\u2705 Model Evaluation Results:\")\n    print(f\"   RMSE: {rmse:.4f}\")\n    print(f\"   MAE: {mae:.4f}\")\n    print(f\"   R\u00b2: {r2:.4f}\")\n\n    # Calculate a quality score (higher is better)\n    r2_norm = max(0, r2)\n    rmse_score = max(0, 1.0 - rmse)\n    quality_score = (0.7 * r2_norm) + (0.3 * rmse_score)\n    print(f\"\u2705 Model quality score: {quality_score:.4f}\")\n\n    return quality_score\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-load-data": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "load_data"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas==1.5.3' 'numpy==1.23.5' 'gcsfs==2025.3.2' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef load_data(data_path: str, output_data: Output[Dataset]):\n    \"\"\"Loads wine data from a CSV file located in GCS.\"\"\"\n    import pandas as pd\n\n    def load_data_from_gcs(gcs_path: str) -> pd.DataFrame:\n        try:\n            df = pd.read_csv(gcs_path)\n            print(f\"\u2705 Loaded wine data from GCS with shape: {df.shape}\")\n            return df\n        except Exception as e:\n            raise FileNotFoundError(\n                f\"\u274c Failed to load GCS file: {gcs_path}. Error: {e}\")\n\n    df = load_data_from_gcs(data_path)\n\n    # Add ID column if it doesn't exist\n    if 'id' not in df.columns:\n        df['id'] = range(1, len(df) + 1)\n\n    df.to_csv(output_data.path, index=False)\n    print(f\"\u2705 Wine data saved to {output_data.path}\")\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-preprocess-data": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "preprocess_data"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas==1.5.3' 'numpy==1.23.5' 'scikit-learn==1.0.1' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef preprocess_data(input_data: Input[Dataset],\n                    output_data: Output[Dataset],\n                    train_data: Output[Dataset],\n                    test_data: Output[Dataset]):\n    \"\"\"Preprocesses the wine data for the prediction model.\"\"\"\n    import os\n    import pandas as pd\n    import re\n    from sklearn.model_selection import train_test_split\n\n    # Load the input data\n    df = pd.read_csv(input_data.path)\n    print(f\"\u2705 Loaded input data with shape: {df.shape}\")\n\n    # Handle missing values in categorical columns\n    categorical_features = ['Country', 'Region', 'Type', 'Style', 'Grape']\n    for col in categorical_features:\n        if col in df.columns:\n            df[col] = df[col].fillna('Unknown')\n\n    # Extract numeric price values if available\n    if \"Price\" in df.columns:\n        df[\"price_numeric\"] = df[\"Price\"].apply(\n            lambda x: float(re.search(r'(\\d+\\.?\\d*)', str(x)).group(1))\n            if pd.notna(x) and re.search(r'\\d+\\.?\\d*', str(x))\n            else 0\n        )\n    else:\n        df[\"price_numeric\"] = 0\n\n    # Create target column if needed\n    if 'Rating' not in df.columns:\n        # Create a synthetic rating based on price (just for demonstration purposes)\n        df['Rating'] = df['price_numeric'] * 0.2 + 3.0\n        df.loc[df['Rating'] > 5.0, 'Rating'] = 5.0\n        print(\"\u26a0\ufe0f Created synthetic Rating column based on price\")\n\n    # Split data into train/test\n    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n    # Save train/test data\n    train_df.to_csv(train_data.path, index=False)\n    test_df.to_csv(test_data.path, index=False)\n\n    # Save combined data for the pipeline output\n    df.to_csv(output_data.path, index=False)\n\n    print(\n        f\"\u2705 Preprocessed train data saved at {train_data.path} with shape {train_df.shape}\")\n    print(\n        f\"\u2705 Preprocessed test data saved at {test_data.path} with shape {test_df.shape}\")\n    print(f\"\u2705 Combined preprocessed data saved at {output_data.path}\")\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-register-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "register_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform>=1.22.1' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef register_model(\n    model_artifact: Input[Model],\n    registered_model: Output[Model],\n    model_display_name: str,\n    serving_container_image_uri: str = \"europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\",\n    project: str = \"dev2-ea8f\",\n    region: str = \"europe-west2\",\n):\n    \"\"\"Registers the wine rating model to Vertex AI Model Registry.\"\"\"\n    from google.cloud import aiplatform\n\n    aiplatform.init(project=project, location=region)\n\n    try:\n        model = aiplatform.Model.upload(\n            display_name=model_display_name,\n            artifact_uri=model_artifact.uri,\n            serving_container_image_uri=serving_container_image_uri,\n        )\n        print(f\"\u2705 Model registered: {model.resource_name}\")\n\n        # Store model information\n        registered_model.uri = model.resource_name\n        registered_model.metadata[\"display_name\"] = model_display_name\n        registered_model.metadata[\"resource_name\"] = model.resource_name\n        # Pass through other metadata\n        for key, value in model_artifact.metadata.items():\n            if key not in registered_model.metadata:\n                registered_model.metadata[key] = value\n\n    except Exception as e:\n        print(f\"\u274c Error registering model: {e}\")\n        raise e\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-train-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas==1.5.3' 'numpy==1.23.5' 'scikit-learn==1.0.1' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_model(\n    train_data: Input[Dataset],\n    output_model: Output[Model]\n):\n    \"\"\"Trains a wine rating prediction model using RandomForestRegressor.\"\"\"\n    import os\n    import pandas as pd\n    import numpy as np\n    import pickle\n    from sklearn.ensemble import RandomForestRegressor\n    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n    from sklearn.compose import ColumnTransformer\n    from sklearn.pipeline import Pipeline\n\n    # Load the preprocessed training data\n    df = pd.read_csv(train_data.path)\n    print(f\"\u2705 Loaded training data with shape: {df.shape}\")\n\n    # Define categorical and numeric features\n    categorical_features = ['Country', 'Region', 'Type', 'Style', 'Grape']\n    categorical_features = [\n        col for col in categorical_features if col in df.columns]\n\n    numeric_features = ['price_numeric']\n    numeric_features = [col for col in numeric_features if col in df.columns]\n\n    # Save the feature order for inference\n    feature_order = numeric_features + categorical_features\n\n    # Target is Rating\n    target = 'Rating'\n\n    # Create feature preprocessing pipeline\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', StandardScaler(), [i for i, col in enumerate(\n                feature_order) if col in numeric_features]),\n            ('cat', OneHotEncoder(handle_unknown='ignore'), [\n             i for i, col in enumerate(feature_order) if col in categorical_features])\n        ],\n        remainder='passthrough'\n    )\n\n    # Create model pipeline that uses array indices instead of column names\n    model_pipeline = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n    ])\n\n    # Fit the model with array data\n    X = df[feature_order].values  # Convert to numpy array\n    y = df[target].values\n    model_pipeline.fit(X, y)\n    print(\"\u2705 Model trained successfully\")\n\n    # Save the model using pickle\n    file_name = output_model.path + \".pkl\"\n    with open(file_name, 'wb') as file:\n        pickle.dump(model_pipeline, file)\n\n    # Add metadata\n    output_model.metadata[\"framework\"] = \"sklearn\"\n    output_model.metadata[\"feature_order\"] = str(feature_order)\n    output_model.metadata[\"target\"] = target\n\n    print(f\"\u2705 Model trained and saved to {file_name}\")\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-upload-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "upload_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-storage' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef upload_model(model_artifact: Input[Model], uploaded_model_artifact: Output[Model]):\n    \"\"\"Uploads the wine rating model artifact.\"\"\"\n    import os\n    import shutil\n\n    # Create a directory structure for the model\n    model_dir = os.path.dirname(uploaded_model_artifact.path)\n    os.makedirs(model_dir, exist_ok=True)\n\n    # Define the path where the model file will be saved\n    model_file_path = os.path.join(model_dir, \"model.pkl\")\n    source_path = model_artifact.path + \".pkl\"\n\n    # Copy the model file\n    print(f\"Copying model from {source_path} to {model_file_path}\")\n    shutil.copy(source_path, model_file_path)\n\n    # Set the URI to the directory containing the model\n    uploaded_model_artifact.uri = model_dir\n    uploaded_model_artifact.metadata.update(model_artifact.metadata)\n\n    print(f\"\u2705 Model uploaded to directory: {model_dir}\")\n    print(f\"\u2705 Model URI set to: {uploaded_model_artifact.uri}\")\n\n"
          ],
          "image": "python:3.9"
        }
      }
    }
  },
  "pipelineInfo": {
    "description": "End-to-end pipeline for training, evaluating and deploying a wine rating prediction model.",
    "name": "wine-rating-prediction-pipeline"
  },
  "root": {
    "dag": {
      "tasks": {
        "condition-1": {
          "componentRef": {
            "name": "comp-condition-1"
          },
          "dependentTasks": [
            "evaluate-model",
            "train-model"
          ],
          "inputs": {
            "artifacts": {
              "pipelinechannel--train-model-output_model": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "output_model",
                  "producerTask": "train-model"
                }
              }
            },
            "parameters": {
              "pipelinechannel--endpoint_display_name": {
                "componentInputParameter": "endpoint_display_name"
              },
              "pipelinechannel--evaluate-model-Output": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "evaluate-model"
                }
              },
              "pipelinechannel--evaluation_threshold": {
                "componentInputParameter": "evaluation_threshold"
              },
              "pipelinechannel--model_display_name": {
                "componentInputParameter": "model_display_name"
              },
              "pipelinechannel--project": {
                "componentInputParameter": "project"
              },
              "pipelinechannel--region": {
                "componentInputParameter": "region"
              }
            }
          },
          "taskInfo": {
            "name": "check_model_quality"
          },
          "triggerPolicy": {
            "condition": "inputs.parameter_values['pipelinechannel--evaluate-model-Output'] >= inputs.parameter_values['pipelinechannel--evaluation_threshold']"
          }
        },
        "evaluate-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-evaluate-model"
          },
          "dependentTasks": [
            "preprocess-data",
            "train-model"
          ],
          "inputs": {
            "artifacts": {
              "model_artifact": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "output_model",
                  "producerTask": "train-model"
                }
              },
              "test_data": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "test_data",
                  "producerTask": "preprocess-data"
                }
              }
            }
          },
          "taskInfo": {
            "name": "evaluate-model"
          }
        },
        "load-data": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-load-data"
          },
          "inputs": {
            "parameters": {
              "data_path": {
                "componentInputParameter": "data_path"
              }
            }
          },
          "taskInfo": {
            "name": "load-data"
          }
        },
        "preprocess-data": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-preprocess-data"
          },
          "dependentTasks": [
            "load-data"
          ],
          "inputs": {
            "artifacts": {
              "input_data": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "output_data",
                  "producerTask": "load-data"
                }
              }
            }
          },
          "taskInfo": {
            "name": "preprocess-data"
          }
        },
        "train-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-model"
          },
          "dependentTasks": [
            "preprocess-data"
          ],
          "inputs": {
            "artifacts": {
              "train_data": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "train_data",
                  "producerTask": "preprocess-data"
                }
              }
            }
          },
          "taskInfo": {
            "name": "train-model"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "batch_input_uri": {
          "defaultValue": "gs://model-output-wine-dev2-ea8f/batch-inputs/wine_input.csv",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "batch_output_uri": {
          "defaultValue": "gs://model-output-wine-dev2-ea8f/batch-outputs/",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "data_path": {
          "parameterType": "STRING"
        },
        "endpoint_display_name": {
          "defaultValue": "wine-rating-endpoint",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "evaluation_threshold": {
          "defaultValue": 0.6,
          "isOptional": true,
          "parameterType": "NUMBER_DOUBLE"
        },
        "model_display_name": {
          "defaultValue": "wine-rating-model",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "project": {
          "defaultValue": "dev2-ea8f",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "region": {
          "defaultValue": "europe-west2",
          "isOptional": true,
          "parameterType": "STRING"
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.12.1"
}