{
  "components": {
    "comp-condition-1": {
      "dag": {
        "tasks": {
          "deploy-model": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-deploy-model"
            },
            "dependentTasks": [
              "register-model"
            ],
            "inputs": {
              "artifacts": {
                "model_registry_name": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "registered_model",
                    "producerTask": "register-model"
                  }
                }
              },
              "parameters": {
                "endpoint_display_name": {
                  "componentInputParameter": "pipelinechannel--endpoint_display_name"
                },
                "machine_type": {
                  "componentInputParameter": "pipelinechannel--machine_type"
                },
                "max_replica_count": {
                  "componentInputParameter": "pipelinechannel--max_replica_count"
                },
                "min_replica_count": {
                  "componentInputParameter": "pipelinechannel--min_replica_count"
                },
                "project": {
                  "componentInputParameter": "pipelinechannel--project"
                },
                "region": {
                  "componentInputParameter": "pipelinechannel--region"
                }
              }
            },
            "taskInfo": {
              "name": "deploy-model"
            }
          },
          "register-model": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-register-model"
            },
            "dependentTasks": [
              "save-model"
            ],
            "inputs": {
              "artifacts": {
                "model_artifact": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "uploaded_model_artifact",
                    "producerTask": "save-model"
                  }
                }
              },
              "parameters": {
                "model_display_name": {
                  "componentInputParameter": "pipelinechannel--model_display_name"
                },
                "model_serving_image": {
                  "componentInputParameter": "pipelinechannel--model_serving_image"
                },
                "project": {
                  "componentInputParameter": "pipelinechannel--project"
                },
                "region": {
                  "componentInputParameter": "pipelinechannel--region"
                }
              }
            },
            "taskInfo": {
              "name": "register-model"
            }
          },
          "save-model": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-save-model"
            },
            "inputs": {
              "artifacts": {
                "model_artifact": {
                  "componentInputArtifact": "pipelinechannel--train-model-output_model"
                }
              }
            },
            "taskInfo": {
              "name": "save-model"
            }
          }
        }
      },
      "inputDefinitions": {
        "artifacts": {
          "pipelinechannel--train-model-output_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "pipelinechannel--endpoint_display_name": {
            "parameterType": "STRING"
          },
          "pipelinechannel--evaluate-model-Output": {
            "parameterType": "NUMBER_DOUBLE"
          },
          "pipelinechannel--evaluation_threshold": {
            "parameterType": "NUMBER_DOUBLE"
          },
          "pipelinechannel--machine_type": {
            "parameterType": "STRING"
          },
          "pipelinechannel--max_replica_count": {
            "parameterType": "NUMBER_INTEGER"
          },
          "pipelinechannel--min_replica_count": {
            "parameterType": "NUMBER_INTEGER"
          },
          "pipelinechannel--model_display_name": {
            "parameterType": "STRING"
          },
          "pipelinechannel--model_serving_image": {
            "parameterType": "STRING"
          },
          "pipelinechannel--project": {
            "parameterType": "STRING"
          },
          "pipelinechannel--region": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-deploy-model": {
      "executorLabel": "exec-deploy-model",
      "inputDefinitions": {
        "artifacts": {
          "model_registry_name": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "endpoint_display_name": {
            "parameterType": "STRING"
          },
          "machine_type": {
            "parameterType": "STRING"
          },
          "max_replica_count": {
            "parameterType": "NUMBER_INTEGER"
          },
          "min_replica_count": {
            "parameterType": "NUMBER_INTEGER"
          },
          "project": {
            "parameterType": "STRING"
          },
          "region": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "endpoint": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-evaluate-model": {
      "executorLabel": "exec-evaluate-model",
      "inputDefinitions": {
        "artifacts": {
          "model_artifact": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          },
          "test_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "NUMBER_DOUBLE"
          }
        }
      }
    },
    "comp-load-data": {
      "executorLabel": "exec-load-data",
      "inputDefinitions": {
        "parameters": {
          "data_path": {
            "description": "GCS path to the wine dataset (gs://bucket/path/file.csv)",
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-preprocess-data": {
      "executorLabel": "exec-preprocess-data",
      "inputDefinitions": {
        "artifacts": {
          "input_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "random_state": {
            "defaultValue": 42.0,
            "isOptional": true,
            "parameterType": "NUMBER_INTEGER"
          },
          "test_size": {
            "defaultValue": 0.2,
            "isOptional": true,
            "parameterType": "NUMBER_DOUBLE"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "test_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "train_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-register-model": {
      "executorLabel": "exec-register-model",
      "inputDefinitions": {
        "artifacts": {
          "model_artifact": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "model_display_name": {
            "parameterType": "STRING"
          },
          "model_serving_image": {
            "parameterType": "STRING"
          },
          "project": {
            "parameterType": "STRING"
          },
          "region": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "registered_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-save-model": {
      "executorLabel": "exec-save-model",
      "inputDefinitions": {
        "artifacts": {
          "model_artifact": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "uploaded_model_artifact": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-train-model": {
      "executorLabel": "exec-train-model",
      "inputDefinitions": {
        "artifacts": {
          "train_data": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "n_estimators": {
            "parameterType": "NUMBER_INTEGER"
          },
          "random_state": {
            "parameterType": "NUMBER_INTEGER"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "output_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    }
  },
  "deploymentSpec": {
    "executors": {
      "exec-deploy-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "deploy_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef deploy_model(\n    model_registry_name: Input[Model],\n    endpoint: Output[Model],\n    endpoint_display_name: str,\n    project: str,\n    region: str,\n    machine_type: str,\n    min_replica_count: int,\n    max_replica_count: int,\n):\n    \"\"\"Deploys a model to Vertex AI Endpoint.\"\"\"\n    # pylint: disable=import-outside-toplevel\n    from google.cloud import aiplatform\n\n    aiplatform.init(project=project, location=region)\n    model_name = model_registry_name.metadata.get(\"resource_name\")\n    if not model_name:\n        print(\"ERROR: Model resource_name not found in metadata\")\n        raise ValueError(\"ERROR: Model resource_name is missing from metadata.\")\n    try:\n        model = aiplatform.Model(model_name)\n        print(f\"DEBUG: Retrieved model: {model.resource_name}\")\n    except Exception as e:\n        print(f\"ERROR: retrieving model: {e}\")\n        raise e\n    deployed_model_display_name = (\n        f\"{model_registry_name.metadata.get('display_name', 'model')}-deployed\"\n    )\n    try:\n        endpoints = aiplatform.Endpoint.list(\n            filter=f'display_name=\"{endpoint_display_name}\"',\n            order_by=\"create_time desc\",\n            project=project,\n            location=region,\n        )\n        if endpoints:\n            endpoint_to_use = endpoints[0]\n            print(\n                f\"DEBUG: Using existing model endpoint: {endpoint_to_use.resource_name}\"\n            )\n        else:\n            endpoint_to_use = aiplatform.Endpoint.create(\n                display_name=endpoint_display_name, project=project, location=region\n            )\n            print(f\"INFO: Created new endpoint: {endpoint_to_use.resource_name}\")\n        print(\"DEBUG: Starting deployment of model to endpoint...\")\n        endpoint_to_use.deploy(\n            model=model,\n            deployed_model_display_name=deployed_model_display_name,\n            machine_type=machine_type,\n            min_replica_count=min_replica_count,\n            max_replica_count=max_replica_count,\n            traffic_split={\"0\": 100},\n        )\n        print(f\"INFO: Model deployed to endpoint: {endpoint_to_use.resource_name}\")\n        endpoint.uri = endpoint_to_use.resource_name\n    except Exception as e:\n        print(f\"ERROR: Model deployment error: {e}\")\n        if \"endpoint_to_use\" in locals():\n            endpoint.uri = endpoint_to_use.resource_name\n        raise e\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-evaluate-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "evaluate_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'numpy' 'scikit-learn' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef evaluate_model(model_artifact: Input[Model], test_data: Input[Dataset]) -> float:\n    \"\"\"Evaluates the wine rating prediction model.\"\"\"\n    # pylint: disable=import-outside-toplevel,too-many-locals\n    import joblib\n    import pandas as pd\n    import numpy as np\n    import logging\n    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n    try:\n        logging.info(\"Starting model evaluation\")\n\n        # Load model\n        model_path = model_artifact.path + \".joblib\"\n        logging.info(\"Loading trained model\")\n        try:\n            with open(model_path, \"rb\") as file:\n                model = joblib.load(file)\n            logging.info(\"Model loaded successfully\")\n        except Exception as e:\n            logging.error(\"Failed to load model: %s\", e)\n            raise\n\n        # Load test data\n        test_df = pd.read_csv(test_data.path)\n        logging.info(\n            \"Loaded test data: %s rows, %s columns\", test_df.shape[0], test_df.shape[1]\n        )\n\n        # Get features from metadata or use defaults\n        features_str = model_artifact.metadata.get(\"features\", \"\")\n        if features_str:\n            import ast\n\n            features = ast.literal_eval(features_str)\n        else:\n            categorical_features = [\"Country\", \"Region\", \"Type\", \"Style\", \"Grape\"]\n            categorical_features = [\n                col for col in categorical_features if col in test_df.columns\n            ]\n            numeric_features = [\"price_numeric\"]\n            numeric_features = [\n                col for col in numeric_features if col in test_df.columns\n            ]\n            features = numeric_features + categorical_features\n\n        target = model_artifact.metadata.get(\"target\", \"Rating\")\n        logging.info(\"Using %s features for evaluation\", len(features))\n\n        # Make predictions\n        test_features = test_df[features]\n        test_target = test_df[target]\n        predictions = model.predict(test_features)\n\n        # Calculate metrics\n        mse = mean_squared_error(test_target, predictions)\n        rmse = np.sqrt(mse)\n        mae = mean_absolute_error(test_target, predictions)\n        r2 = r2_score(test_target, predictions)\n\n        logging.info(\n            \"Evaluation Results - RMSE: %.4f, MAE: %.4f, R\u00b2: %.4f\", rmse, mae, r2\n        )\n\n        # Calculate quality score (higher = better)\n        r2_norm = max(0, r2)\n        rmse_score = max(0, 1.0 - rmse)\n        quality_score = (0.7 * r2_norm) + (0.3 * rmse_score)\n\n        logging.info(\"Model quality score: %.4f\", quality_score)\n        logging.info(\"Model evaluation completed successfully\")\n\n        return quality_score\n\n    except Exception as e:\n        logging.error(\"Model evaluation failed: %s\", e)\n        raise\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-load-data": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "load_data"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'google-cloud-storage' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef load_data(data_path: str, output_data: Output[Dataset]) -> None:\n    \"\"\"\n    Load wine quality data from Google Cloud Storage.\n    Args:\n        data_path: GCS path to the wine dataset (gs://bucket/path/file.csv)\n        output_data: Output dataset artifact for downstream components\n    \"\"\"\n    # pylint: disable=import-outside-toplevel\n    import pandas as pd\n    from google.cloud import storage\n    import io\n    import logging\n\n    try:\n        # Validate input\n        if not data_path or not data_path.startswith(\"gs://\"):\n            raise ValueError(\"data_path must be a valid GCS URL starting with 'gs://'\")\n\n        logging.info(\"Loading data from: %s\", data_path)\n\n        # Parse GCS path\n        gcs_path_parts = data_path.replace(\"gs://\", \"\").split(\"/\")\n        bucket_name = gcs_path_parts[0]\n        blob_name = \"/\".join(gcs_path_parts[1:])\n\n        # Load data from GCS\n        client = storage.Client()\n        bucket = client.bucket(bucket_name)\n        blob = bucket.blob(blob_name)\n        content = blob.download_as_text()\n        df = pd.read_csv(io.StringIO(content))\n\n        # Validate data\n        if df.empty:\n            raise ValueError(\"Loaded dataset is empty\")\n\n        logging.info(\"Data loaded: %s rows, %s columns\", df.shape[0], df.shape[1])\n\n        # Add ID column if missing\n        if \"id\" not in df.columns:\n            df[\"id\"] = range(1, len(df) + 1)\n\n        # Save processed data\n        df.to_csv(output_data.path, index=False)\n        logging.info(\"Data loading completed successfully\")\n\n    except Exception as e:\n        logging.error(\"Data loading failed: %s\", e)\n        raise\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-preprocess-data": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "preprocess_data"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'numpy' 'scikit-learn' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef preprocess_data(\n    input_data: Input[Dataset],\n    output_data: Output[Dataset],\n    train_data: Output[Dataset],\n    test_data: Output[Dataset],\n    test_size: float = 0.2,\n    random_state: int = 42,\n):\n    \"\"\"Preprocesses the wine data for the prediction model.\"\"\"\n    # pylint: disable=import-outside-toplevel\n    import pandas as pd\n    import re\n    import logging\n    from sklearn.model_selection import train_test_split\n\n    try:\n        logging.info(\"Starting data preprocessing\")\n\n        # Load data\n        df = pd.read_csv(input_data.path)\n        logging.info(\"Loaded data: %d rows, %d columns\", df.shape[0], df.shape[1])\n\n        # Data cleanup (handle missing columns & handle null price)\n        categorical_features = [\"Country\", \"Region\", \"Type\", \"Style\", \"Grape\"]\n        for col in categorical_features:\n            if col in df.columns:\n                df[col] = df[col].fillna(\"Unknown\")\n\n        # Process price column\n        if \"Price\" in df.columns:\n            df[\"price_numeric\"] = df[\"Price\"].apply(\n                lambda x: (\n                    float(re.search(r\"(\\d+\\.?\\d*)\", str(x)).group(1))\n                    if pd.notna(x) and re.search(r\"\\d+\\.?\\d*\", str(x))\n                    else 0\n                )\n            )\n            logging.info(\"Processed Price column to numeric values\")\n        else:\n            df[\"price_numeric\"] = 0\n            logging.warning(\"Price column not found, using default value 0\")\n\n        # Target column (rating) for final prediction\n        if \"Rating\" not in df.columns:\n            df[\"Rating\"] = df[\"price_numeric\"] * 0.2 + 3.0\n            df.loc[df[\"Rating\"] > 5.0, \"Rating\"] = 5.0\n            logging.warning(\"Created synthetic Rating column based on price\")\n        else:\n            logging.info(\"Using existing Rating column\")\n\n        # Split data\n        train_df, test_df = train_test_split(\n            df, test_size=test_size, random_state=random_state\n        )\n        logging.info(\n            \"Train: %d rows, Test: %d rows\", train_df.shape[0], test_df.shape[0]\n        )\n\n        # Save datasets\n        train_df.to_csv(train_data.path, index=False)\n        test_df.to_csv(test_data.path, index=False)\n        df.to_csv(output_data.path, index=False)\n\n        logging.info(\"Data preprocessing completed successfully\")\n\n    except Exception as e:\n        logging.error(\"Data loading failed: %s\", e)\n        raise\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-register-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "register_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef register_model(\n    model_artifact: Input[Model],\n    registered_model: Output[Model],\n    model_display_name: str,\n    project: str,\n    region: str,\n    model_serving_image: str,\n):\n    \"\"\"Registers the wine rating model to Vertex AI Model Registry.\"\"\"\n    # pylint: disable=import-outside-toplevel\n    from google.cloud import aiplatform\n    import logging\n\n    try:\n        logging.info(\"Starting model registration\")\n        logging.info(\"Registering model %s to Vertex AI\", model_display_name)\n\n        # Initialize Vertex AI\n        aiplatform.init(project=project, location=region)\n\n        # Upload model to registry\n        logging.info(\"Uploading model to Vertex AI Model Registry\")\n        model = aiplatform.Model.upload(\n            display_name=model_display_name,\n            artifact_uri=model_artifact.uri,\n            serving_container_image_uri=model_serving_image,\n            serving_container_predict_route=\"/predict\",\n            serving_container_health_route=\"/health\",\n        )\n\n        logging.info(\"Model registered successfully\")\n\n        # Set registered model metadata\n        registered_model.uri = model.resource_name\n        registered_model.metadata[\"display_name\"] = model_display_name\n        registered_model.metadata[\"resource_name\"] = model.resource_name\n\n        # Copy original metadata\n        metadata_count = 0\n        for key, value in model_artifact.metadata.items():\n            if key not in registered_model.metadata:\n                registered_model.metadata[key] = value\n                metadata_count += 1\n\n        logging.info(\"Copied %s metadata items\", metadata_count)\n        logging.info(\"Model registration completed successfully\")\n\n    except Exception as e:\n        logging.error(\"Data loading failed: %s\", e)\n        raise\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-save-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "save_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-storage' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef save_model(model_artifact: Input[Model], uploaded_model_artifact: Output[Model]):\n    \"\"\"Uploads the wine rating model artifact.\"\"\"\n    # pylint: disable=import-outside-toplevel\n    import os\n    import logging\n\n    try:\n        logging.info(\"Starting model save process\")\n\n        # Define paths\n        source_path = model_artifact.path + \".joblib\"\n        model_dir = os.path.dirname(uploaded_model_artifact.path)\n        model_file_path = os.path.join(model_dir, \"model.joblib\")\n\n        logging.info(\"Preparing model directory\")\n        os.makedirs(model_dir, exist_ok=True)\n\n        # Copy model file\n        logging.info(\"Copying model file\")\n        with open(source_path, \"rb\") as source_file:\n            model_data = source_file.read()\n        with open(model_file_path, \"wb\") as target_file:\n            target_file.write(model_data)\n\n        logging.info(\"Model file copied successfully\")\n\n        # Set model URI\n        uploaded_model_artifact.uri = model_dir\n\n        # Copy metadata\n        metadata_count = 0\n        for key, value in model_artifact.metadata.items():\n            try:\n                uploaded_model_artifact.metadata[key] = value\n                metadata_count += 1\n            except (TypeError, ValueError) as metadata_error:\n                logging.warning(\n                    \"Failed to copy metadata for key '%s': %s\", key, metadata_error\n                )\n\n        logging.info(\"Copied %s metadata items\", metadata_count)\n        logging.info(\"Model save completed successfully\")\n\n    except Exception as e:\n        logging.error(\"Model save failed: %s\", e)\n        raise\n\n"
          ],
          "image": "python:3.9"
        }
      },
      "exec-train-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'numpy' 'scikit-learn' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_model(\n    train_data: Input[Dataset],\n    output_model: Output[Model],\n    n_estimators: int,\n    random_state: int,\n):\n    \"\"\"Trains a wine rating prediction model using RandomForestRegressor.\"\"\"\n    # pylint: disable=import-outside-toplevel,too-many-locals\n    import pandas as pd\n    import joblib\n    import logging\n    from sklearn.ensemble import RandomForestRegressor\n    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n    from sklearn.compose import ColumnTransformer\n    from sklearn.pipeline import Pipeline\n\n    try:\n        logging.info(\"Starting model training\")\n\n        # Load training data\n        df = pd.read_csv(train_data.path)\n        logging.info(\n            \"Loaded training data: %s rows, %s columns\", df.shape[0], df.shape[1]\n        )\n\n        # Define features\n        categorical_features = [\"Country\", \"Region\", \"Type\", \"Style\", \"Grape\"]\n        categorical_features = [\n            col for col in categorical_features if col in df.columns\n        ]\n        numeric_features = [\"price_numeric\"]\n        numeric_features = [col for col in numeric_features if col in df.columns]\n        feature_order = numeric_features + categorical_features\n        target = \"Rating\"\n\n        logging.info(\n            \"Features - Numeric: %s, Categorical: %s\",\n            len(numeric_features),\n            len(categorical_features),\n        )\n\n        # Create preprocessing pipeline\n        preprocessor = ColumnTransformer(\n            transformers=[\n                (\n                    \"num\",\n                    StandardScaler(),\n                    [\n                        i\n                        for i, col in enumerate(feature_order)\n                        if col in numeric_features\n                    ],\n                ),\n                (\n                    \"cat\",\n                    OneHotEncoder(handle_unknown=\"ignore\"),\n                    [\n                        i\n                        for i, col in enumerate(feature_order)\n                        if col in categorical_features\n                    ],\n                ),\n            ],\n            remainder=\"passthrough\",\n        )\n\n        # model pipeline\n        model_pipeline = Pipeline(\n            steps=[\n                (\"preprocessor\", preprocessor),\n                (\n                    \"model\",\n                    RandomForestRegressor(\n                        n_estimators=n_estimators, random_state=random_state\n                    ),\n                ),\n            ]\n        )\n\n        # Prepare training data\n        features_data = df[feature_order].values\n        target_data = df[target].values\n        logging.info(\"Training RandomForest with %s estimators\", n_estimators)\n\n        # Train model\n        model_pipeline.fit(features_data, target_data)\n        logging.info(\"Model training completed successfully\")\n\n        # Save model\n        file_name = output_model.path + \".joblib\"\n        with open(file_name, \"wb\") as file:\n            joblib.dump(model_pipeline, file)\n\n        # Set model metadata\n        output_model.metadata[\"framework\"] = \"sklearn\"\n        output_model.metadata[\"feature_order\"] = str(feature_order)\n        output_model.metadata[\"target\"] = target\n        logging.info(\"Model saved successfully\")\n\n    except Exception as e:\n        logging.error(\"Model training failed: %s\", e)\n        raise\n\n"
          ],
          "image": "python:3.9"
        }
      }
    }
  },
  "pipelineInfo": {
    "description": "E2E Wine Rating Demo Pipeline",
    "name": "wine-quality-online-prediction-pipeline"
  },
  "root": {
    "dag": {
      "tasks": {
        "condition-1": {
          "componentRef": {
            "name": "comp-condition-1"
          },
          "dependentTasks": [
            "evaluate-model",
            "train-model"
          ],
          "inputs": {
            "artifacts": {
              "pipelinechannel--train-model-output_model": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "output_model",
                  "producerTask": "train-model"
                }
              }
            },
            "parameters": {
              "pipelinechannel--endpoint_display_name": {
                "componentInputParameter": "endpoint_display_name"
              },
              "pipelinechannel--evaluate-model-Output": {
                "taskOutputParameter": {
                  "outputParameterKey": "Output",
                  "producerTask": "evaluate-model"
                }
              },
              "pipelinechannel--evaluation_threshold": {
                "componentInputParameter": "evaluation_threshold"
              },
              "pipelinechannel--machine_type": {
                "componentInputParameter": "machine_type"
              },
              "pipelinechannel--max_replica_count": {
                "componentInputParameter": "max_replica_count"
              },
              "pipelinechannel--min_replica_count": {
                "componentInputParameter": "min_replica_count"
              },
              "pipelinechannel--model_display_name": {
                "componentInputParameter": "model_display_name"
              },
              "pipelinechannel--model_serving_image": {
                "componentInputParameter": "model_serving_image"
              },
              "pipelinechannel--project": {
                "componentInputParameter": "project"
              },
              "pipelinechannel--region": {
                "componentInputParameter": "region"
              }
            }
          },
          "taskInfo": {
            "name": "model deployment"
          },
          "triggerPolicy": {
            "condition": "inputs.parameter_values['pipelinechannel--evaluate-model-Output'] >= inputs.parameter_values['pipelinechannel--evaluation_threshold']"
          }
        },
        "evaluate-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-evaluate-model"
          },
          "dependentTasks": [
            "preprocess-data",
            "train-model"
          ],
          "inputs": {
            "artifacts": {
              "model_artifact": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "output_model",
                  "producerTask": "train-model"
                }
              },
              "test_data": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "test_data",
                  "producerTask": "preprocess-data"
                }
              }
            }
          },
          "taskInfo": {
            "name": "evaluate-model"
          }
        },
        "load-data": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-load-data"
          },
          "inputs": {
            "parameters": {
              "data_path": {
                "componentInputParameter": "data_path"
              }
            }
          },
          "taskInfo": {
            "name": "load-data"
          }
        },
        "preprocess-data": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-preprocess-data"
          },
          "dependentTasks": [
            "load-data"
          ],
          "inputs": {
            "artifacts": {
              "input_data": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "output_data",
                  "producerTask": "load-data"
                }
              }
            },
            "parameters": {
              "random_state": {
                "componentInputParameter": "random_state"
              },
              "test_size": {
                "componentInputParameter": "test_size"
              }
            }
          },
          "taskInfo": {
            "name": "preprocess-data"
          }
        },
        "train-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-model"
          },
          "dependentTasks": [
            "preprocess-data"
          ],
          "inputs": {
            "artifacts": {
              "train_data": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "train_data",
                  "producerTask": "preprocess-data"
                }
              }
            },
            "parameters": {
              "n_estimators": {
                "componentInputParameter": "n_estimators"
              },
              "random_state": {
                "componentInputParameter": "random_state"
              }
            }
          },
          "taskInfo": {
            "name": "train-model"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "data_path": {
          "description": "GCS path to training data",
          "parameterType": "STRING"
        },
        "endpoint_display_name": {
          "description": "Display name for the endpoint",
          "parameterType": "STRING"
        },
        "evaluation_threshold": {
          "description": "Threshold for model evaluation",
          "parameterType": "NUMBER_DOUBLE"
        },
        "machine_type": {
          "description": "Machine type for training",
          "parameterType": "STRING"
        },
        "max_replica_count": {
          "description": "Maximum replicas for serving",
          "parameterType": "NUMBER_INTEGER"
        },
        "min_replica_count": {
          "description": "Minimum replicas for serving",
          "parameterType": "NUMBER_INTEGER"
        },
        "model_display_name": {
          "description": "Display name for the model",
          "parameterType": "STRING"
        },
        "model_serving_image": {
          "description": "Container image for serving",
          "parameterType": "STRING"
        },
        "n_estimators": {
          "description": "Number of estimators for random forest",
          "parameterType": "NUMBER_INTEGER"
        },
        "project": {
          "description": "GCP project ID",
          "parameterType": "STRING"
        },
        "random_state": {
          "description": "Random seed",
          "parameterType": "NUMBER_INTEGER"
        },
        "region": {
          "description": "GCP region",
          "parameterType": "STRING"
        },
        "test_size": {
          "description": "Test split size",
          "parameterType": "NUMBER_DOUBLE"
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.12.1"
}